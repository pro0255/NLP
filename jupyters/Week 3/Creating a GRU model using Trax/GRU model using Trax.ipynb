{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eight-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trax\n",
    "from trax import layers as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intelligent-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp = tl.Serial(\n",
    "  tl.Dense(128),\n",
    "  tl.Relu(),\n",
    "  tl.Dense(10),\n",
    "  tl.LogSoftmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accurate-madrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Dense_128\n",
      "  Serial[\n",
      "    Relu\n",
      "  ]\n",
      "  Dense_10\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "heavy-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "vocab_size = 256\n",
    "model_dimension = 512\n",
    "n_layers = 2\n",
    "\n",
    "GRU = tl.Serial(\n",
    "      tl.ShiftRight(mode=mode), # Do remember to pass the mode parameter if you are using it for interence/test as default is train \n",
    "      tl.Embedding(vocab_size=vocab_size, d_feature=model_dimension),\n",
    "      [tl.GRU(n_units=model_dimension) for _ in range(n_layers)], # You can play around n_layers if you want to stack more GRU layers together\n",
    "      tl.Dense(n_units=vocab_size),\n",
    "      tl.LogSoftmax()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protecting-basics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total layers: 6\n",
      "\n",
      "========\n",
      "Serial.sublayers_0: Serial[\n",
      "  ShiftRight(1)\n",
      "]\n",
      "\n",
      "========\n",
      "Serial.sublayers_1: Embedding_256_512\n",
      "\n",
      "========\n",
      "Serial.sublayers_2: GRU_512\n",
      "\n",
      "========\n",
      "Serial.sublayers_3: GRU_512\n",
      "\n",
      "========\n",
      "Serial.sublayers_4: Dense_256\n",
      "\n",
      "========\n",
      "Serial.sublayers_5: LogSoftmax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_layers(model, layer_prefix=\"Serial.sublayers\"):\n",
    "    print(f\"Total layers: {len(model.sublayers)}\\n\")\n",
    "    for i in range(len(model.sublayers)):\n",
    "        print('========')\n",
    "        print(f'{layer_prefix}_{i}: {model.sublayers[i]}\\n')\n",
    "        \n",
    "show_layers(GRU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
